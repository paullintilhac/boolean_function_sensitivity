{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efd5999a-8c66-4a9c-9143-8df9bfbd35df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to load ./HYPERPARAM_TESTS/model_17800.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embeddings): Embedding(2, 30)\n",
       "  (transformer): Sequential(\n",
       "    (0): AttentionBlock(\n",
       "      (attn): CustomMHA(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=60, out_features=60, bias=False)\n",
       "      )\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=60, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=60, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import itertools\n",
    "from transformer import Transformer\n",
    "\n",
    "N=30\n",
    "dropout = .5\n",
    "h=1\n",
    "dim=60\n",
    "l=1\n",
    "f=128\n",
    "ln_eps=1e-5\n",
    "ln=False\n",
    "iter=17800\n",
    "i=2\n",
    "deg=5\n",
    "width=30\n",
    "folderName = \".\"\n",
    "dir_name = os.path.join(folderName,\"HYPERPARAM_TESTS\")\n",
    "seedNum = int(str(i)+str(deg)+str(width))\n",
    "device = \"cuda:0\"\n",
    "rank=0\n",
    "def rboolf(N, width, deg,seed=None):\n",
    "    if seed:\n",
    "        torch.manual_seed(seed)\n",
    "    coefficients = torch.randn(width).to(device)\n",
    "    #print(\"coefficients initial shape: \" + str(coefficients.shape) + \", width: \" + str(width))\n",
    "    coefficients = (coefficients-coefficients.mean())/coefficients.pow(2).sum().sqrt()\n",
    "    \n",
    "    combs = torch.tensor(list(itertools.combinations(torch.arange(N), deg))).to(device)\n",
    "    combs = combs[torch.randperm(len(combs))][:width] # Shuffled\n",
    "    return (coefficients, combs)\n",
    "\n",
    "\n",
    "(coefs, combs) = rboolf(N, width, deg,seed=seedNum)\n",
    "model = Transformer(dropout,N, dim, h, l, f, ln_eps,rank,ln)\n",
    "# Load the state dictionary from a file\n",
    "#try:\n",
    "print(\"trying to load \" + str(dir_name+\"/model_\"+str(iter)+\".pt\"))\n",
    "state_dict = torch.load(dir_name+\"/model_\"+str(iter)+\".pt\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80b5ae4c-9540-429a-bad9-1c8231f26c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top eigs: [7288.19384765625]\n",
      "top eig Hessian: 7288.19384765625, trace Hessian: 22128.338830336084\n",
      "weight norm: 24.587772753739248\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "import copy\n",
    "import random\n",
    "from pyhessian.hessian import hessian\n",
    "import numpy as np\n",
    "\n",
    "def makeBitTensor(x, N):\n",
    "    y = format(x, \"b\")\n",
    "    y = (\"0\"*(N-len(y))) + y\n",
    "    return [int(z) for z in list(y)]\n",
    "    \n",
    "def get_weight_norm(model):\n",
    "       total_norm = 0.0\n",
    "       for p in model.parameters():\n",
    "           if p.requires_grad:\n",
    "               param_norm = p.data.norm(2)\n",
    "               total_norm += param_norm.item() ** 2\n",
    "       return total_norm ** 0.5\n",
    "    \n",
    "def calc_hessian(model, loss_fn, num_samples):\n",
    "        model.eval().to(device)\n",
    "        inputs = torch.tensor([random.randint(0, 2**N-1) for _ in range(num_samples)]).to(device)\n",
    "        targets = func_batch(inputs).to(device)\n",
    "        data = (inputs, targets)        \n",
    "\n",
    "        # Estimate using PyHessian -- very good\n",
    "        hess_mod = hessian(model, loss_fn, data, device=0)\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        top_eigs, top_eigVs = hess_mod.eigenvalues(maxIter = 200)\n",
    "        print(\"top eigs: \" + str(top_eigs))\n",
    "        top_eig = top_eigs[0] \n",
    "        \n",
    "        trace = hess_mod.trace()\n",
    "        return top_eig, np.mean(trace)\n",
    "    \n",
    "def func_batch(x):\n",
    "    binaryTensor = ((torch.tensor([makeBitTensor(y,N) for y in x])-.5)*2)\n",
    "    comps = []\n",
    "    #print(\"self.combs length: \" + str(len(self.combs)))\n",
    "    for elem in combs:\n",
    "        res = torch.tensor([1]*len(x))\n",
    "        for e in elem:\n",
    "            bitCol = binaryTensor[:,e]\n",
    "            res = torch.mul(res, bitCol)\n",
    "        comps.append(res)\n",
    "    comps = torch.transpose(torch.stack(comps),1,0).to(device)\n",
    "    return torch.matmul(comps, coefs).to(device)\n",
    "\n",
    "\n",
    "loss_fn = lambda result, targets: (result-targets).pow(2).mean()\n",
    "    \n",
    "start_time_hessian = time.time()\n",
    "\n",
    "top_eig, trace = calc_hessian(copy.deepcopy(model), loss_fn=loss_fn, num_samples= 1000)\n",
    "print(\"top eig Hessian: \" + str(top_eig)+\", trace Hessian: \" + str(trace))\n",
    "weight_norm = 0\n",
    "weight_norm = get_weight_norm(model)\n",
    "print(\"weight norm: \" + str(weight_norm))\n",
    "#weight_norm = torch.linalg.norm(self.model.weight)\n",
    "top_eig=0\n",
    "trace = 0\n",
    "end_time_hessian = time.time()\n",
    "elapsed_time_hessian = round((end_time_hessian - start_time_hessian)/60,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b15d1572-254e-4bcc-90d1-351275dd52f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: tensor(1.6479)\n"
     ]
    }
   ],
   "source": [
    "def validate( num_samples): \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    inputs = torch.tensor([random.randint(0, 2**N-1) for _ in range(num_samples)]).to(device)\n",
    "    targets = func_batch(inputs).to(device)\n",
    "    result = model(inputs).to(device)\n",
    "    loss = (result - targets).pow(2).mean()\n",
    "    return loss.detach().cpu()\n",
    "    \n",
    "val_loss = validate(1000) \n",
    "print(\"val loss: \" + str(val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
